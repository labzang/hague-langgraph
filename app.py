"""
LangChain Hello World ì• í”Œë¦¬ì¼€ì´ì…˜ with pgvector ì—°ë™

ì´ ì•±ì€ pgvector ë°ì´í„°ë² ì´ìŠ¤ì™€ ì—°ë™í•˜ì—¬ ê°„ë‹¨í•œ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
íŒŒì´ì¬ 3.13 ë²„ì „ ì´ìƒ ì‚¬ìš©
íŒŒì¼ì„ ìˆ˜ì •í•œ í›„
"""

import os
import asyncio
from typing import List
import psycopg2
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_core.vectorstores import VectorStore
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import PGVector
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_core.language_models.base import BaseLanguageModel


class SimpleEmbeddings(Embeddings):
    """ê°„ë‹¨í•œ ë”ë¯¸ ì„ë² ë”© í´ë˜ìŠ¤ (OpenAI API í‚¤ê°€ ì—†ì„ ë•Œ ì‚¬ìš©)"""

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œë“¤ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        return [[0.1, 0.2, 0.3, 0.4, 0.5] for _ in texts]

    def embed_query(self, text: str) -> List[float]:
        """ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        return [0.1, 0.2, 0.3, 0.4, 0.5]


def wait_for_postgres():
    """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
    import time

    max_retries = 30
    retry_count = 0

    while retry_count < max_retries:
        try:
            conn = psycopg2.connect(
                host=os.getenv("POSTGRES_HOST", "postgres"),
                port=os.getenv("POSTGRES_PORT", "5432"),
                database=os.getenv("POSTGRES_DB", "langchain_db"),
                user=os.getenv("POSTGRES_USER", "langchain_user"),
                password=os.getenv("POSTGRES_PASSWORD", "langchain_password")
            )
            conn.close()
            print("âœ… PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!")
            return True
        except psycopg2.OperationalError:
            retry_count += 1
            print(f"â³ PostgreSQL ì—°ê²° ëŒ€ê¸° ì¤‘... ({retry_count}/{max_retries})")
            time.sleep(2)

    raise Exception("PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def setup_vectorstore() -> PGVector:
    """pgvector ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •"""

    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´
    connection_string = (
        f"postgresql://{os.getenv('POSTGRES_USER', 'langchain_user')}:"
        f"{os.getenv('POSTGRES_PASSWORD', 'langchain_password')}@"
        f"{os.getenv('POSTGRES_HOST', 'postgres')}:"
        f"{os.getenv('POSTGRES_PORT', '5432')}/"
        f"{os.getenv('POSTGRES_DB', 'langchain_db')}"
    )

    # ì„ë² ë”© ëª¨ë¸ ì„¤ì • (OpenAI API í‚¤ê°€ ìˆìœ¼ë©´ OpenAI, ì—†ìœ¼ë©´ ë”ë¯¸)
    if os.getenv("OPENAI_API_KEY"):
        embeddings = OpenAIEmbeddings()
        print("ğŸ¤– OpenAI ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        embeddings = SimpleEmbeddings()
        print("ğŸ”§ ë”ë¯¸ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ)")

    # PGVector ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    vectorstore = PGVector(
        connection_string=connection_string,
        embedding_function=embeddings,
        collection_name="langchain_collection",
    )

    return vectorstore


def add_sample_documents(vectorstore: PGVector):
    """ìƒ˜í”Œ ë¬¸ì„œë“¤ì„ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€"""

    sample_docs = [
        Document(
            page_content="LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
            metadata={"source": "langchain_intro", "type": "definition"}
        ),
        Document(
            page_content="pgvectorëŠ” PostgreSQLì—ì„œ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í™•ì¥ì…ë‹ˆë‹¤.",
            metadata={"source": "pgvector_intro", "type": "definition"}
        ),
        Document(
            page_content="DockerëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì»¨í…Œì´ë„ˆë¡œ íŒ¨í‚¤ì§•í•˜ì—¬ ë°°í¬ë¥¼ ì‰½ê²Œ ë§Œë“œëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.",
            metadata={"source": "docker_intro", "type": "definition"}
        ),
        Document(
            page_content="Pythonì€ ë°ì´í„° ê³¼í•™ê³¼ AI ê°œë°œì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
            metadata={"source": "python_intro", "type": "definition"}
        ),
    ]

    print("ğŸ“š ìƒ˜í”Œ ë¬¸ì„œë“¤ì„ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€ ì¤‘...")
    vectorstore.add_documents(sample_docs)
    print("âœ… ìƒ˜í”Œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ!")


def setup_rag_chain(vectorstore: PGVector):
    """RAG (Retrieval-Augmented Generation) ì²´ì¸ ì„¤ì •"""

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:

ì»¨í…ìŠ¤íŠ¸: {context}

ì§ˆë¬¸: {question}

ë‹µë³€:
""")

    # ê²€ìƒ‰ê¸° ì„¤ì •
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

    # LLM ì„¤ì • ë° RAG ì²´ì¸ êµ¬ì„±
    if os.getenv("OPENAI_API_KEY"):
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        print("ğŸ¤– OpenAI GPT ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # ì‹¤ì œ RAG ì²´ì¸ êµ¬ì„±
        rag_chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
    else:
        print("ğŸ”§ ë”ë¯¸ LLMì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ)")

        # ë”ë¯¸ RAG í•¨ìˆ˜ (OpenAI API í‚¤ê°€ ì—†ì„ ë•Œ)
        def dummy_rag_function(question: str) -> str:
            """OpenAI API í‚¤ê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ë”ë¯¸ RAG í•¨ìˆ˜"""
            # invoke ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰
            docs = retriever.invoke(question)
            context = "\n".join([f"- {doc.page_content}" for doc in docs])

            return f"""ğŸ” ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œë“¤:
{context}

ğŸ’¡ ë”ë¯¸ ì‘ë‹µ: ìœ„ì˜ ë¬¸ì„œë“¤ì´ '{question}' ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤.
ì‹¤ì œ AI ì‘ë‹µì„ ë°›ìœ¼ë ¤ë©´ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.
í•˜ì§€ë§Œ ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ì€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!"""

        # RunnableLambdaë¡œ ë˜í•‘í•˜ì—¬ ì²´ì¸ê³¼ í˜¸í™˜ë˜ë„ë¡ í•¨
        rag_chain = RunnableLambda(dummy_rag_function)

    return rag_chain


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ LangChain + pgvector Hello World ì•± ì‹œì‘!")

    # PostgreSQL ì—°ê²° ëŒ€ê¸°
    wait_for_postgres()

    # ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •
    print("ğŸ”§ ë²¡í„°ìŠ¤í† ì–´ ì„¤ì • ì¤‘...")
    vectorstore = setup_vectorstore()

    # ìƒ˜í”Œ ë¬¸ì„œ ì¶”ê°€ (ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸)
    try:
        # ê¸°ì¡´ ë¬¸ì„œ ìˆ˜ í™•ì¸
        existing_docs = vectorstore.similarity_search("test", k=1)
        if not existing_docs:
            add_sample_documents(vectorstore)
        else:
            print("ğŸ“š ê¸°ì¡´ ë¬¸ì„œê°€ ë°œê²¬ë˜ì–´ ìƒ˜í”Œ ë¬¸ì„œ ì¶”ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    except Exception as e:
        print(f"âš ï¸ ê¸°ì¡´ ë¬¸ì„œ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ìƒ˜í”Œ ë¬¸ì„œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤: {e}")
        add_sample_documents(vectorstore)

    # RAG ì²´ì¸ ì„¤ì •
    print("ğŸ”— RAG ì²´ì¸ ì„¤ì • ì¤‘...")
    rag_chain = setup_rag_chain(vectorstore)

    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_questions = [
        "LangChainì´ ë¬´ì—‡ì¸ê°€ìš”?",
        "pgvectorëŠ” ì–´ë–¤ ê¸°ëŠ¥ì„ ì œê³µí•˜ë‚˜ìš”?",
        "Dockerì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "Pythonì´ AI ê°œë°œì— ì¸ê¸° ìˆëŠ” ì´ìœ ëŠ”?",
    ]

    print("\n" + "="*50)
    print("ğŸ¯ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤ì— ëŒ€í•œ ë‹µë³€:")
    print("="*50)

    for i, question in enumerate(test_questions, 1):
        print(f"\nğŸ“ ì§ˆë¬¸ {i}: {question}")
        print("-" * 30)

        try:
            # ëª¨ë“  ê²½ìš°ì— invoke ë©”ì„œë“œ ì‚¬ìš© (RunnableLambdaë„ invokeë¥¼ ì§€ì›)
            answer = rag_chain.invoke(question)

            print(f"ğŸ’¡ ë‹µë³€: {answer}")

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

        print("-" * 30)

    print("\nâœ… Hello World ì•± ì‹¤í–‰ ì™„ë£Œ!")
    print("ğŸ” ë²¡í„° ê²€ìƒ‰ê³¼ RAG ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")

    # Docker í™˜ê²½ì—ì„œëŠ” ëŒ€í™”í˜• ëª¨ë“œ ê±´ë„ˆë›°ê¸°
    if os.getenv("DOCKER_ENV") or not os.isatty(0):
        print("\nğŸ³ Docker í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
        print("ğŸ’¡ ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   docker-compose exec -it langchain_app bash")
        print("   python app.py")
        print("\nğŸ‰ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return

    # ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰
    print("\n" + "="*50)
    print("ğŸ’¬ ëŒ€í™”í˜• ëª¨ë“œ (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ì…ë ¥)")
    print("="*50)

    while True:
        try:
            user_question = input("\nâ“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()

            if user_question.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                break

            if not user_question:
                continue

            print("ğŸ” ê²€ìƒ‰ ì¤‘...")

            # ëª¨ë“  ê²½ìš°ì— invoke ë©”ì„œë“œ ì‚¬ìš©
            answer = rag_chain.invoke(user_question)

            print(f"ğŸ’¡ ë‹µë³€: {answer}")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
