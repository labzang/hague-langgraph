# 환경 변수 설정 예시 파일
# 실제 사용 시 이 파일을 .env로 복사하고 값을 설정하세요

# LLM 설정
# OpenAI 사용 시
LLM_PROVIDER=openai
OPENAI_API_KEY=your_openai_api_key_here

# 로컬 한국어 모델 사용 시
# LLM_PROVIDER=korean_local
# LOCAL_MODEL_DIR=./model

# Midm-2.0-Mini-Instruct 모델 사용 시 (기본 경로: app/model/midm)
# LLM_PROVIDER=midm
# LOCAL_MODEL_DIR=./app/model/midm  # 선택사항: 기본 경로와 다른 곳에 있을 때만

# 한국어 모델 사용 (Ollama)
# USE_OLLAMA=true
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama2

# 한국어 모델 사용 (Hugging Face) - 추천
# USE_HUGGINGFACE=true
# HF_MODEL_NAME=nousresearch/polyglot-ko-3.8b
# USE_QUANTIZATION=true  # GPU 메모리 절약 (4-bit 양자화)

# 임베딩 모델 설정
# USE_OPENAI_EMBEDDINGS=false  # OpenAI 임베딩 사용 안 함
# EMBEDDING_MODEL_NAME=BAAI/bge-small-ko-v1.5  # 한국어 임베딩 모델

# 데이터베이스 설정 (기본값이 docker-compose.yaml과 일치)
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=langchain_db
POSTGRES_USER=langchain_user
POSTGRES_PASSWORD=langchain_password

# pgvector 설정 (api_server.py에서 사용)
PGVECTOR_USER=langchain_user
PGVECTOR_PASSWORD=langchain_password
PGVECTOR_HOST=postgres
PGVECTOR_PORT=5432
PGVECTOR_DATABASE=langchain_db
COLLECTION_NAME=rag_collection

# Next.js 프론트엔드 설정
NEXT_PUBLIC_API_URL=http://localhost:8000
