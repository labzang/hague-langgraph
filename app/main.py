"""FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜."""

import os
import traceback
from contextlib import asynccontextmanager
from typing import List

import psycopg2
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from langchain_community.vectorstores import PGVector
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

try:
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰í•  ë•Œ
    from app.api.models import HealthResponse
    from app.api.routes import search
    from app.config import settings
    from app.router import chat_router
except ImportError:
    # app ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì‹¤í–‰í•  ë•Œ
    from api.models import HealthResponse
    from api.routes import search
    from config import settings
    from router import chat_router


class SimpleEmbeddings(Embeddings):
    """ê°„ë‹¨í•œ ë”ë¯¸ ì„ë² ë”© í´ë˜ìŠ¤ (OpenAI API í‚¤ê°€ ì—†ì„ ë•Œ ì‚¬ìš©)"""

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œë“¤ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        return [[0.1, 0.2, 0.3, 0.4, 0.5] for _ in texts]

    def embed_query(self, text: str) -> List[float]:
        """ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        return [0.1, 0.2, 0.3, 0.4, 0.5]


def wait_for_postgres() -> None:
    """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°.

    Docker ì»¨í…Œì´ë„ˆ ëŒ€ì‹  ì™¸ë¶€(Postgres/Neon ë“±) ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ,
    `Settings.database_url`ì„ ì‚¬ìš©í•´ ì ‘ì†ì„ ì‹œë„í•©ë‹ˆë‹¤.
    """
    import time

    max_retries = 30
    retry_count = 0

    while retry_count < max_retries:
        try:
            # DATABASE_URL í¬í•¨: postgresql://... í˜•íƒœì˜ ì „ì²´ URI ì‚¬ìš©
            conn = psycopg2.connect(settings.database_url)
            conn.close()
            print("[ì„±ê³µ] PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!")
            return
        except psycopg2.OperationalError as exc:
            retry_count += 1
            print(
                f"[ëŒ€ê¸°] PostgreSQL ì—°ê²° ëŒ€ê¸° ì¤‘... ({retry_count}/{max_retries}) - {exc}"
            )
            time.sleep(2)

    raise Exception("PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def setup_vectorstore() -> PGVector:
    """pgvector ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •"""

    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´
    connection_string = (
        f"postgresql://{os.getenv('POSTGRES_USER', 'langchain_user')}:"
        f"{os.getenv('POSTGRES_PASSWORD', 'langchain_password')}@"
        f"{os.getenv('POSTGRES_HOST', 'postgres')}:"
        f"{os.getenv('POSTGRES_PORT', '5432')}/"
        f"{os.getenv('POSTGRES_DB', 'langchain_db')}"
    )

    # ì„ë² ë”© ëª¨ë¸ ì„¤ì • (OpenAI API í‚¤ê°€ ìˆìœ¼ë©´ OpenAI, ì—†ìœ¼ë©´ ë”ë¯¸)
    if os.getenv("OPENAI_API_KEY"):
        embeddings = OpenAIEmbeddings()
        print("[AI] OpenAI ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        embeddings = SimpleEmbeddings()
        print("[ë”ë¯¸] ë”ë¯¸ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ)")

    # PGVector ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    vectorstore = PGVector(
        connection_string=connection_string,
        embedding_function=embeddings,
        collection_name="langchain_collection",
    )

    return vectorstore


def add_sample_documents(vectorstore: PGVector):
    """ìƒ˜í”Œ ë¬¸ì„œë“¤ì„ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€"""

    sample_docs = [
        Document(
            page_content="LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
            metadata={"source": "langchain_intro", "type": "definition"},
        ),
        Document(
            page_content="pgvectorëŠ” PostgreSQLì—ì„œ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í™•ì¥ì…ë‹ˆë‹¤.",
            metadata={"source": "pgvector_intro", "type": "definition"},
        ),
        Document(
            page_content="DockerëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì»¨í…Œì´ë„ˆë¡œ íŒ¨í‚¤ì§•í•˜ì—¬ ë°°í¬ë¥¼ ì‰½ê²Œ ë§Œë“œëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.",
            metadata={"source": "docker_intro", "type": "definition"},
        ),
        Document(
            page_content="Pythonì€ ë°ì´í„° ê³¼í•™ê³¼ AI ê°œë°œì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
            metadata={"source": "python_intro", "type": "definition"},
        ),
    ]

    print("[ì¶”ê°€] ìƒ˜í”Œ ë¬¸ì„œë“¤ì„ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€ ì¤‘...")
    vectorstore.add_documents(sample_docs)
    print("[ì™„ë£Œ] ìƒ˜í”Œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ!")


def setup_rag_chain(vectorstore: PGVector):
    """RAG (Retrieval-Augmented Generation) ì²´ì¸ ì„¤ì •"""

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:

ì»¨í…ìŠ¤íŠ¸: {context}

ì§ˆë¬¸: {question}

ë‹µë³€:
""")

    # ê²€ìƒ‰ê¸° ì„¤ì •
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

    # LLM ì„¤ì • ë° RAG ì²´ì¸ êµ¬ì„±
    if os.getenv("OPENAI_API_KEY"):
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        print("[AI] OpenAI GPT ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # ì‹¤ì œ RAG ì²´ì¸ êµ¬ì„±
        rag_chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
    else:
        print("[ë”ë¯¸] ë”ë¯¸ LLMì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ)")

        # ë”ë¯¸ RAG í•¨ìˆ˜ (OpenAI API í‚¤ê°€ ì—†ì„ ë•Œ)
        def dummy_rag_function(question: str) -> str:
            """OpenAI API í‚¤ê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ë”ë¯¸ RAG í•¨ìˆ˜"""
            # invoke ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰
            docs = retriever.invoke(question)
            context = "\n".join([f"- {doc.page_content}" for doc in docs])

            return f"""[ê²€ìƒ‰] ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œë“¤:
{context}

[ë”ë¯¸ì‘ë‹µ] ìœ„ì˜ ë¬¸ì„œë“¤ì´ '{question}' ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤.
ì‹¤ì œ AI ì‘ë‹µì„ ë°›ìœ¼ë ¤ë©´ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.
í•˜ì§€ë§Œ ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ì€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!"""

        # RunnableLambdaë¡œ ë˜í•‘í•˜ì—¬ ì²´ì¸ê³¼ í˜¸í™˜ë˜ë„ë¡ í•¨
        rag_chain = RunnableLambda(dummy_rag_function)

    return rag_chain


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜."""
    # ì‹œì‘ ì‹œ
    print("[ì‹œì‘] FastAPI RAG ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì¤‘...")

    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
    db_connected = False
    try:
        wait_for_postgres()
        db_connected = True
        print("[ì„¤ì •] ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì¤‘...")

        # ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •
        vectorstore = setup_vectorstore()

        # ìƒ˜í”Œ ë¬¸ì„œ ì¶”ê°€ (ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸)
        try:
            # ê¸°ì¡´ ë¬¸ì„œ ìˆ˜ í™•ì¸
            existing_docs = vectorstore.similarity_search("test", k=1)
            if not existing_docs:
                add_sample_documents(vectorstore)
            else:
                print("[ì •ë³´] ê¸°ì¡´ ë¬¸ì„œê°€ ë°œê²¬ë˜ì–´ ìƒ˜í”Œ ë¬¸ì„œ ì¶”ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        except Exception as e:
            print(f"[ê²½ê³ ] ê¸°ì¡´ ë¬¸ì„œ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ìƒ˜í”Œ ë¬¸ì„œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤: {e}")
            add_sample_documents(vectorstore)

        # RAG ì²´ì¸ ì„¤ì •
        print("[ì„¤ì •] RAG ì²´ì¸ ì„¤ì • ì¤‘...")
        rag_chain = setup_rag_chain(vectorstore)

        # ì•± ìƒíƒœì— ì €ì¥
        app.state.vectorstore = vectorstore
        app.state.rag_chain = rag_chain

    except Exception as e:
        print(f"[ê²½ê³ ] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨, ë”ë¯¸ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤: {e}")
        # ë”ë¯¸ ë²¡í„°ìŠ¤í† ì–´ì™€ RAG ì²´ì¸ ì„¤ì •
        app.state.vectorstore = None
        app.state.rag_chain = None
        db_connected = False

    app.state.db_connected = db_connected

    # ìˆœí™˜ ì˜ì¡´ì„±ì„ í”¼í•˜ê¸° ìœ„í•´ ì§€ì—° ì„í¬íŠ¸
    try:
        from app.core.llm import create_llm_from_config
    except ImportError:
        from core.llm import create_llm_from_config

    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì„±ê³µí•œ ê²½ìš°ì—ë§Œ ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹œë„
    if db_connected:
        try:
            try:
                from app.core.vectorstore import initialize_vectorstore
            except ImportError:
                from core.vectorstore import initialize_vectorstore
            initialize_vectorstore()
        except Exception as e:
            print(f"[ê²½ê³ ] ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # ğŸ”§ LLM ìƒì„± ë° ì „ì—­ ì„¤ì •

    llm = create_llm_from_config(settings)
    if llm:
        print("[ì„±ê³µ] ì‚¬ìš©ì ì •ì˜ LLMì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        # ì „ì—­ ë³€ìˆ˜ë¡œ ì €ì¥í•˜ì—¬ ë¼ìš°í„°ì—ì„œ ì‚¬ìš©
        app.state.llm = llm
    else:
        print("[ê²½ê³ ] LLM ì„¤ì •ì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. ê¸°ë³¸ ë™ì‘ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        app.state.llm = None

    # ğŸ”§ Chat Service (QLoRA) ì´ˆê¸°í™”
    if settings.use_chat_service and settings.chat_model_path:
        try:
            try:
                from app.service.chat_service import create_qlora_chat_service
            except ImportError:
                from service.chat_service import create_qlora_chat_service

            print("[ì„¤ì •] QLoRA Chat Service ì´ˆê¸°í™” ì¤‘...")
            chat_service = create_qlora_chat_service(
                model_name_or_path=settings.chat_model_path,
                adapter_path=settings.chat_adapter_path,
            )
            app.state.chat_service = chat_service
            print("[ì„±ê³µ] QLoRA Chat Service ì´ˆê¸°í™” ì™„ë£Œ!")
        except Exception as e:
            print(f"[ê²½ê³ ] Chat Service ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            app.state.chat_service = None
    else:
        app.state.chat_service = None
        if settings.use_chat_service:
            print("[ê²½ê³ ] Chat Serviceë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ CHAT_MODEL_PATHë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

    print("[ì™„ë£Œ] ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤€ë¹„ ì™„ë£Œ!")
    yield
    # ì¢…ë£Œ ì‹œ
    print("[ì¢…ë£Œ] ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì¤‘...")


# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app = FastAPI(
    title=settings.app_name,
    version=settings.app_version,
    description="LangChainê³¼ pgvectorë¥¼ ì‚¬ìš©í•œ RAG API ì„œë²„",
    lifespan=lifespan,
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ì˜ˆì™¸ í•¸ë“¤ëŸ¬ ì¶”ê°€


@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """ì „ì—­ ì˜ˆì™¸ í•¸ë“¤ëŸ¬ - ëª¨ë“  ì˜ˆì™¸ë¥¼ ìºì¹˜í•˜ì—¬ ë¡œê¹…."""
    error_msg = str(exc)
    print(f"[ì˜¤ë¥˜] ì „ì—­ ì˜ˆì™¸ ë°œìƒ: {error_msg}")
    print(f"[ì˜¤ë¥˜] ìš”ì²­ ê²½ë¡œ: {request.url.path}")
    print(f"[ì˜¤ë¥˜] ìš”ì²­ ë©”ì„œë“œ: {request.method}")
    traceback.print_exc()
    return JSONResponse(
        status_code=500,
        content={
            "detail": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {error_msg}",
            "path": request.url.path,
        },
    )


# API ë¼ìš°í„° ë“±ë¡
app.include_router(search.router)
app.include_router(chat_router.router)


@app.get("/", tags=["root"])
async def root() -> dict:
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸."""
    return {
        "message": "LangChain RAG APIì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!",
        "docs": "/docs",
        "health": "/health",
    }


@app.get("/hello-world", tags=["demo"])
async def hello_world() -> dict:
    """Hello World ë°ëª¨ ì—”ë“œí¬ì¸íŠ¸ - app.py ê¸°ëŠ¥ í†µí•©"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœ í™•ì¸
        if not app.state.db_connected or not app.state.rag_chain:
            return {
                "message": "LangChain + pgvector Hello World ë°ëª¨ (ë”ë¯¸ ëª¨ë“œ)",
                "results": [
                    {
                        "question": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœ",
                        "answer": "ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜(DATABASE_URL ë˜ëŠ” POSTGRES_*)ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
                        "status": "warning",
                    }
                ],
                "status": "partial",
                "db_connected": False,
            }

        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
        test_questions = [
            "LangChainì´ ë¬´ì—‡ì¸ê°€ìš”?",
            "pgvectorëŠ” ì–´ë–¤ ê¸°ëŠ¥ì„ ì œê³µí•˜ë‚˜ìš”?",
            "Dockerì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "Pythonì´ AI ê°œë°œì— ì¸ê¸° ìˆëŠ” ì´ìœ ëŠ”?",
        ]

        results = []

        for question in test_questions:
            try:
                # RAG ì²´ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
                answer = app.state.rag_chain.invoke(question)
                results.append(
                    {"question": question, "answer": answer, "status": "success"}
                )
            except Exception as e:
                results.append(
                    {
                        "question": question,
                        "answer": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                        "status": "error",
                    }
                )

        return {
            "message": "LangChain + pgvector Hello World ë°ëª¨",
            "results": results,
            "status": "completed",
            "db_connected": True,
        }

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Hello World ë°ëª¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        )


@app.get("/health", response_model=HealthResponse, tags=["health"])
async def health() -> HealthResponse:
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸."""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸ (DATABASE_URL ê¸°ë°˜)
        conn = psycopg2.connect(settings.database_url)
        conn.close()
        db_status = "connected"
    except Exception:
        db_status = "disconnected"

    return HealthResponse(
        status="healthy",
        version=settings.app_version,
        database=db_status,
        openai_configured=settings.openai_api_key is not None,
    )


# python -m app.main
if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.debug,
    )
